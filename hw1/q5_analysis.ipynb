{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Analysis (20 points)\n",
    "By now you should know how to train networks from scratch or using from pre-trained models. You should also understand the relative performance in either scenarios. Needless to say, the performance of these models is stronger than previous non-deep architectures used until 2012. However, final performance is not the only metric we care about. It is important to get some intuition of what these models are really learning. Lets try some standard techniques.\n",
    "\n",
    "\n",
    "**FEEL FREE TO WRITE UTIL CODE IN ANOTHER FILE AND IMPORT IN THIS NOTEBOOK FOR EASE OF READABILITY**\n",
    "\n",
    "## 5.1 Nearest Neighbors (7 pts)\n",
    "Pick 3 images from PASCAL test set from different classes, and compute 4 nearest neighbors over the entire test set for each of them. You should compare the following feature representations to find the nearest neighbors:\n",
    "1. The features before the final fc layer from the ResNet (finetuned from ImageNet). It is the features right before the final class label output.\n",
    "2. pool5 features from the CaffeNet (trained from scratch)\n",
    "\n",
    "You may use the [this nearest neighbor function](https://scikit-learn.org/stable/modules/neighbors.html).\n",
    "Plot the raw images of the ones you picked and their nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import trainer\n",
    "from utils import ARGS\n",
    "from simple_cnn import SimpleCNN\n",
    "from voc_dataset import VOCDataset\n",
    "\n",
    "# Load all the test images. Pick 3 indices.\n",
    "dataset = VOCDataset(split='test', inp_size=224)\n",
    "loader = DataLoader(dataset, batch_size=512, num_workers=8)\n",
    "indices = np.random.choice(len(dataset), size=3)\n",
    "torch_images = []\n",
    "caffenet_features = []\n",
    "resnet_features = []\n",
    "\n",
    "# Calculate the features for all the test images.\n",
    "class CaffeNet(nn.Module):\n",
    "    def __init__(self, num_classes=20, inp_size=224, c_dim=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 96, 11, stride=4, padding=\"valid\")\n",
    "        self.pool1 = nn.MaxPool2d(3, 2)\n",
    "        self.conv2 = nn.Conv2d(96, 256, 5, stride=1, padding=\"same\")\n",
    "        self.pool2 = nn.MaxPool2d(3, 2)\n",
    "        self.conv3 = nn.Conv2d(256, 384, 3, stride=1, padding=\"same\")\n",
    "        self.conv4 = nn.Conv2d(384, 384, 3, stride=1, padding=\"same\")\n",
    "        self.conv5 = nn.Conv2d(384, 256, 3, stride=1, padding=\"same\")\n",
    "        self.pool5 = nn.MaxPool2d(3, 2)\n",
    "        \n",
    "        self.fc6 = nn.Linear(6400, 4096)\n",
    "        self.dropout6 = nn.Dropout(0.5)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.dropout7 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc8 = nn.Linear(4096, 20)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.forward_features(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout7(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool5(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout6(x)\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "    \n",
    "class PretrainedResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = models.resnet18(pretrained=True)\n",
    "        self.pretrained.fc = nn.Linear(512, 20)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.pretrained(x)\n",
    "        return self.sig(logits)\n",
    "    \n",
    "    def forward_features(self, x):\n",
    "        x = self.pretrained.conv1(x)\n",
    "        x = self.pretrained.bn1(x)\n",
    "        x = self.pretrained.relu(x)\n",
    "        x = self.pretrained.maxpool(x)\n",
    "        x = self.pretrained.layer1(x)\n",
    "        x = self.pretrained.layer2(x)\n",
    "        x = self.pretrained.layer3(x)\n",
    "        x = self.pretrained.layer4(x)\n",
    "        x = self.pretrained.avgpool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "caffenet = CaffeNet()\n",
    "caffenet.load_state_dict(torch.load(\"models/checkpoint-caffenet_scratch-epoch50.pth\"))\n",
    "resnet = PretrainedResnet()\n",
    "resnet.load_state_dict(torch.load(\"models/checkpoint-resnet_finetuned-epoch10.pth\"))\n",
    "\n",
    "# Fine the nearest neighbors for the 3 images you picked.\n",
    "\n",
    "\n",
    "# Plot the images and their neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 t-SNE visualization of intermediate features (7pts)\n",
    "We can also visualize how the feature representations specialize for different classes. Take 1000 random images from the test set of PASCAL, and extract caffenet (scratch) fc7 features from those images. Compute a 2D [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) projection of the features, and plot them with each feature color coded by the GT class of the corresponding image. If multiple objects are active in that image, compute the color as the ”mean” color of the different classes active in that image. Legend the graph with the colors for each object class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot t-SNE here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Are some classes harder? (6pts)\n",
    "Show the per-class performance of your caffenet (scratch) and ResNet (finetuned) models. This is an open-ended question and you may use any performance metric that makes sense. Try to explain, by observing examples from the dataset, why some classes are harder or easier than the others (consider the easiest and hardest class). Do some classes see large gains due to pre-training? Can you explain why that might happen?\n",
    "\n",
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
